{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN, GRU,TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os, gc\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "def model_creator(type_of_RNN=\"LSTM\", dense_size=14, input_shape=(1,16), dropout=True, drop_rate=0.5, loss='categorical_crossentropy', optimizer=\"Adam\", lr=0.01, number_of_classes=2):\n",
    "    model = Sequential()\n",
    "    if type_of_RNN==\"LSTM\":\n",
    "        model.add(LSTM(dense_size, input_shape=input_shape))\n",
    "    if type_of_RNN==\"RNN\":\n",
    "        model.add(SimpleRNN(dense_size, input_shape=input_shape))\n",
    "    if type_of_RNN==\"GRU\":\n",
    "        model.add(GRU(dense_size, input_shape=input_shape))\n",
    "    if dropout:\n",
    "        model.add(Dropout(drop_rate))\n",
    "    model.add(Dense(number_of_classes, activation='softmax'))\n",
    "    \n",
    "    if optimizer==\"Adam\":\n",
    "        optimizer=optimizers.Adam(lr)\n",
    "    if optimizer==\"RMSprop\":\n",
    "        optimizer=optimizers.RMSprop(lr)\n",
    "    if optimizer==\"SGD\":\n",
    "        optimizer=optimizers.SGD(lr)\n",
    "    if optimizer==\"Adagrad\":\n",
    "        optimizer=optimizers.Adagrad(lr)\n",
    "    if optimizer==\"Adadelta\":\n",
    "        optimizer=optimizers.Adadelta(lr)\n",
    "    model.compile(loss=loss, optimizer=optimizer, \n",
    "                  metrics=[])\n",
    "    return model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "my_classifier = KerasClassifier(model_creator, batch_size=1024)\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={\n",
    "                                    'type_of_RNN': [\"LSTM\",\"RNN\",\"GRU\"],\n",
    "                                     'optimizer': [\"Adam\",\"RMSprop\"],\n",
    "                                     'epochs': [10],\n",
    "                                     'validation_split':[0.1],\n",
    "                                     'batch_size':[1024],\n",
    "                                     'number_of_classes':[2],\n",
    "                                     'dropout': [False, True],\n",
    "                                     'dense_size': [14],\n",
    "                                     'lr': [0.001]\n",
    "        \n",
    "                        },\n",
    "                         cv=1,\n",
    "                         verbose=27,\n",
    "                         scoring='neg_log_loss',\n",
    "                         n_jobs=1)\n",
    "validator.fit(X_train[:10000], to_categorical(y_train[:10000,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"COD_SEER_model\"\n",
    "model_checkpoint = ModelCheckpoint(\"./COD_SEER_model/weights_%s-{epoch:02d}.h5\" % (name), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "csv_logger = CSVLogger('training_{name}.log')\n",
    "# learning rate schedule\n",
    "def smoothed_categorical_crossentropy(y_true, y_pred):\n",
    "    return keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0.2) \n",
    "def step_decay(epoch, lr):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.8\n",
    "    epochs_drop = 10.0\n",
    "    lrate = lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model_n = Sequential()\n",
    "model_n.add(SimpleRNN(14, input_shape=(1,16)))\n",
    "model_n.add(Dense(1, activation='linear'))\n",
    "model_n.compile(loss=\"mse\", optimizer=optimizers.Adam(0.001), metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.TruePositives(),tf.keras.metrics.SpecificityAtSensitivity(1.0) ])\n",
    "\n",
    "histo_=model_n.fit(X_train_selected,y_train[:,1], epochs=10, batch_size=1024, validation_split=0.01,callbacks=[lrate,csv_logger,model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn=model_all.predict(X_train_selected, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRNNSurvivalFunction(x):\n",
    "    kmf_ = KaplanMeierFitter() \n",
    "    kmf_.fit(X_train_selected[:,:,-1], y_pred_rnn[:,1]+x, label=\"Predicted Kaplan Meier Estimate - RNN - \")\n",
    "\n",
    "    kmf = KaplanMeierFitter() \n",
    "    kmf.fit(X_train_selected[:,:,-1], Y_train_selected[:,1], label=\"Predicted Kaplan Meier Estimate - True - \")\n",
    "    \n",
    "    RNN_KM_estimate = kmf_.confidence_interval_.to_dict()\n",
    "    Normal_KM_estimate = kmf.confidence_interval_.to_dict()\n",
    "    \n",
    "    return np.mean(np.subtract(list(RNN_KM_estimate[key_RNN[0]].values()),list(Normal_KM_estimate[key_KM[0]].values())))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "res=optimize.minimize_scalar(GetF,method='brent') #Get local minimum for the best calibrated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "kmf_ = KaplanMeierFitter() \n",
    "kmf_.fit(X_train_selected[:,:,-1], y_pred_rnn[:,1]+res.x, label=\"Predicted Kaplan Meier Estimate - RNN - \")\n",
    "a2=kmf_.plot()\n",
    "kmf = KaplanMeierFitter() \n",
    "kmf.fit(X_train_selected[:,:,-1], Y_train_selected[:,1], label=\"Predicted Kaplan Meier Estimate - True - \")\n",
    "a2=kmf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
